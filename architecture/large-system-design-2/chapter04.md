### 4장 요약

# 4장. 분산 메시지 큐

> 시스템 설계 면접에 단골로 출제되는 문제인, 분산 메시지 큐 설계
> 
- 현대적 소프트웨어 아키텍처를 따르는 시스템은 잘 정의된 인터페이스를 경계로 나뉜 작고 독립적인 블록들로 구성
- 메시지 큐는 이 `블록 사이의 통신과 조율 담당`
- 유명 분산 메시지 큐:
    - 아파치 Kakka
    - 아파티 RocketMQ
    - 아파치 RabbitMQ
    - 아파치 Pulsar
    - 아파치 ActiveMQ
    - ZeroMQ

### 메시지 큐 장점:

- 결합도 완화(decoupling): 각각을 독립적으로 갱신 가능
- 규모 확장성 개선:
    - 아래의 컴포넌트를 시스템 규모에 대한 트래픽 부하에 맞게 독립적으로 늘릴 수 있음
        - 생산자(producer): 메시지 큐에 데이터 생산
        - 소비자(consumer): 큐에서 메시지를 소비
- 가용성 개선
- 성능 개선:
    - 비동기 통신이 쉽게 가능해짐
    - 서로를 기다릴 필요가 없어짐

### 메시지 큐 vs 이벤트 스트리밍 플랫폼

> 이번 장에서는 데이터 장기 보관, 메시지 반복 소비 등의 부가 기능을 갖춘 분산 메시지 큐 설계
> 
- 엄밀히 말하면 카프카와 펄사는 이벤트 스트리밍 플랫폼
- 지원하는 기능이 서로 수렴하며 구분이 희미해지고있음

# 1단계: 문제 이해 및 설계 범위 확정

> 프로듀서는 메시지를 큐에 보내고, 컨슈머는 큐에서 메시지를 꺼낸다.
> 
- 기본 기능 외에도 성능, 메시지 전달 방식, 데이터 보관 기관 등 고려할 사항 다양함
- 메시지의 형태와 평균 크기
- 텍스트 메시지 / 멀티미디어 지원
- 메시지의 반복적 소비 가능성
- 여러 컨슈머가 수신 가능해야 하는지
- 전달된 순서대로 소비되어야 하는지
- 데이터의 지속성 보장 여부
- 데이터의 보관 기간
- 프로듀서와 컨슈머의 수
- 메시지 전달 방식
    - 최대 한 번
    - 최소 한 번
    - 정확히 한 번
- 대역폭
- 엔드 투 엔드 지연시간

### 전통적인 메시지 큐와 다른 점

- RabbitMQ와 같은 전통적인 메시지 큐는 이벤트 스트리밍 플랫폼처럼 메시지 보관 문제를 중요하게 다루지 않음
- 전통적인 큐는 메시지가 소비자에 전달되기 충분한 기간 동안만 메모리에 보관
- 처리 용량을 넘어선 메시지 → 디스크에 보관 (이벤트 스트리밍 플랫폼이 감당하는 용량보다는 아주 낮은 수준)
- 전통적인 메시지 큐는 메시지 전달 순서도 보존하지 않음 → 생산된 순서와 소비되는 순서는 다를 수 있음

# 2단계: 개략적 설계안 제시 및 동의 구하기

> 생산자 → 메시지 생산 → 메시지 큐 ← 구독 ← 소비자
생산자 → 메시지 생산 → 메시지 큐 → 소비 → 소비자
> 
- 생산자는 메시지를 메시지 큐에 발행
- 소비자는 큐를 구독하고 구독한 메시지를 소비
- 메시지 큐는 생산자와 소비자 사이의 결합을 느슨하게 하는 서비스
    - 생산자와 소비자의 독립적인 운영 및 규모 확장을 가능하게함
- C/S 모델 관점
    - 프로듀서, 컨슈머: 클라이언트
    - 메시지 큐: 서버 역할
    - 클라이언트와 서버는 네트워크를 통해 통신

### 메시지 모델:

- `일대일` (point-to-point) 모델:
    - 오직 하나의 컨슈머만 소비 가능
    - Acknowledge → 메시지는 큐에서 삭제
    - 데이터 보관 지원 X
    - 컨슈머 그룹을 통해 지원 가능
- `발행-구독` (publish-subscribe) 모델:
    
    > 토픽(topic): 메시지를 주제별로 정리하는데 사용
    각 토픽은 메시지 큐 서비스 전반에 고유한 이름을 갖음
    > 
    - 메시지를 보내고 받을 때, 토픽에 보내고 받음
    - 토픽에 전달된 메시지는 해당 토픽을 구독하는 모든 소비자에 전달

### 토픽, 파티션, 브로커

- 메시지는 토픽에 보관 → 토픽에 보관되는 데이터의 양이 커져서 감당하기 힘들면?
    - 파티션 → 샤딩 기법 활용
        - 토픽을 여러 파티션으로 분할
        - 메시지를 모든 파티션에 균등하게 나눠 보냄
        - 파티션은 메시지 큐 클러스터 내의 서버에 고르게 분산 배치
        - 파티션을 유지하는 서버는 보통 `브로커`(borker)라고 함
        - 파티션을 브로커에 분산하는 것 → 높은 규모 확장성을 달성하는 비결!
        - 토픽의 용량을 확장하고 싶으면 파티션 개수를 늘리면 됨
        - 각 토픽 파티션은 FIFO 큐처럼 동작
        - **같은 파티션 안에서는 메시지 순서 유지**
        - 파티션 내에서의 메시지 위치를 `오프셋`(offset)이라고 함
        - 메시지에 user_id 같은 키를 붙일 수 있음 → 같은 키를 가진 모든 메시지는 같은 파티션으로 보내짐
        - 키가 없는 메시지는 무작위로 선택된 파티션으로 전송
        - 토픽을 구독하는 소비자는 하나 이상의 파티션에서 데이터를 가져옴
        - 토픽을 구독하는 소비자가 여럿인 경우, 각 구독자는 해당 토픽을 구성하는 파티션의 일부를 담당
        - 이러한 소비자들을 해당 토픽의 `소비자 그룹`(consumer group)이라고 부름

### 소비자 그룹

> 본 설계안은 일대일 모델과 발행-구독 모델을 전부 지원해야함
> 
- 하나의 소비자 그룹은 여러 토픽을 구독할 수 있고 오프셋을 별도로 관리
- 같은 그룹 내의 소비자는 메시지를 병렬로 소비 가능
- 데이터를 병렬로 읽으면 대역폭 측면에서는 좋지만 같은 파티션 안에 있는 메시지를 순서대로 소비할 수 없음
- 파티션은 가장 작은 저장 단위이므로 미리 충분한 파티션을 할당해 두면 파티션의 수를 동적으로 늘리는 일을  피할 수 있음

## 개략적 설계안

### 클라이언트

- 생산자: 메시지를 특정 토픽으로 전달
- 소비자 그룹: 토픽을 구독하고 메시지를 소비

### 핵심 서비스 및 저장소

- 브로커: 파티션들을 유지, 하나의 파티션은 특정 토픽에 대한 메시지의 부분 집합을 유지
- 저장소:
    - 데이터 저장소: 메시지는 파티션 내 데이터 저장소에 보관
    - 상태 저장소: 소비자 상태는 해당 저장소에 유지
    - 메타데이터 저장소: 토픽 설정, 토픽 속성 등은 해당 저장소에 유지
- 조정 서비스(coordination service):
    - 서비스 디스커버리: 어떤 브로커가 살아있는지 알려줌
    - 리더 선출:
        - 브로커 가운데 하나는 `컨트롤러 역할`을 담당
        - 한 클러스터에는 반드시 활성 상태 컨트롤러가 하나 있어야함
        - 해당 컨트롤러가 파티션 배치를 책임짐
    - `아파치 주키퍼`, `etcd`가 보통 컨트롤러 선출을 담당하는 컴포넌트

# 3단계: 상세 설계

- 회전 디스크(rotational disk)의 높은 순차 탐색 성능과 현대적 운영체제가 제공하는 적극적 디스크 캐시 전략을 잘 이용하는 `디스크 기반 자료 구조`(on-disk data structure) 활용
- 메시지가 생산자로부터 소비자에게 전달되는 순간까지 아무 수정 없이도 전송이 가능하도록 하는 메시지 자료 구조 설계 및 활용 → 전송 데이터의 양이 막대한 경우에 메시지 복사에 드는 비용 최소화를 위함
- 일괄 처리(batching)를 우선하는 시스템 설계:
    - 소규모의 I/O가 많으면 높은 대역폭을 지원하기 어려움
    - 생산자는 메시지를 일괄 전송하고 메시지 큐는 그 메시지들을 더 큰 단위로 묶어 보관
    - 소비자도 가능하면 메시지를 일괄 수신하도록 설계

## 데이터 저장소

> 메시지를 어떻게 지속적으로 저장할지 상세하게 알아보자
> 

### 메시지 큐의 트래픽 패턴

- 읽기와 쓰기가 빈번하게 일어남
- 갱신/삭제 연산은 발생 X
    - 전통적인 메시지 큐는 메시지가 신속하게 전달되지 못해 큐가 제때 비워지지 않는 경우를 제외하면 메시지를 지속적으로 보관하지 않음
    - 큐에서 메시지가 제때 소비되기 시작하면 저장된 메시지에 대한 삭제 연산이 발생하기는 할 것임
- 순차적인 읽기/쓰기가 대부분

### 선택지 1: 데이터 베이스

- RDBS:
    - 토픽별로 테이블 생성
    - 토픽에 보내는 메시지는 해당 테이블에 새로운 레코드로 추가
    - 데이터 저장 요구사항을 맞출 수는 있음
    - 하지만 이상적인 방법일 수는 없음:
        - 읽기 연산과 쓰기 연산이 동시에 대규모로 빈번하게 발생하는 상황을 잘 처리하는 데이터베이스 설계가 어려움
- NoSQL:
    - 토픽별로 컬렉션 생성
    - 토픽에 보내는 메시지는 하나의 문서가 됨

### 선택지 2: 쓰기 우선 로그(Write-Ahead Log, WAL)

> WAL은 새로운 항목이 추가되기만 하는(append-only) 일반 파일
> 
- WAL은 다양한 시스템에서 사용되는 기술
    - MySQL의 복구 로그(redo log)가 WAL로 구현
    - 아파치 주키퍼도 해당 기술을 활용
- 지속성을 보장해야하는 메시지는 디스크에 WAL로 보관할 것을 추천
    - WAL에 대한 접근 패턴은 읽기/쓰기 모두 순차적
    - 접근 패턴이 순차적일 때 디스크는 아주 좋은 성능을 보여줌
    - 회전식 디스크 기반 저장장치는 큰 용량을 저렴한 가격에 제공
- 새로운 메시지는 파티션 꼬리 부분에 추가되며, 오프셋은 그 결과로 점진적으로 증가
    - 가장 쉬운 방법은 로그 파일 줄 번호(line number)를 오프셋으로 사용
    - 하지만 파일의 크기도 무한정 커질 수는 없으니, `세그먼트 단위`로 나누는 것이 바람직
    - 세그먼트를 사용하는 경우 새 메시지는 활성 상태의 세그먼트 파일에만 추가
    - 해당 세그먼트의 크기가 일정 한계에 도달하면 새 활성 세그먼트 파일이 만들어져 새로운 메시지를 수용하고 종전까지 활성 상태였던 세그먼트 파일은 다른 나머지 세그먼트 파일과 마찬가지로 비활성화 상태로 바뀜
    - 비활성 세그먼트는 읽기 요청만 처리
    - 낡은 비활성 세그먼트 파일은 보관 기한이 만료되거나 용량 한계에 도달하면 삭제해 버릴 수 있음
    - 같은 파티션에 속한 세그먼트 파일은 Partition-{:partition_id} 폴더 아래에 저장

### 디스크 성능 관련 유의사항

> 데이터 장기 보관에 대한 요구사항으로 본 설계안은 디스크 드라이브를 활용하여 다량의 데이터를 보관
> 
- 회전식 디스크가 느리다는 것은 널리 퍼진 편견임
- 회전식 디스크가 정말로 느려지는 것은 데이터 접근 패턴이 무작위일 때임
- 순차적 데이터 접근 패턴을 적극 활용하는 디스크 기반 자료 구조를 사용하면, RAID로 구성된 현대적 디스크 드라이브에서 수백 MB/sec 수준의 읽기/쓰기 성능을 달성하는 것은 어렵지 않음
- 요구사항을 충족하는 데는 이 정도면 충분하며, 비용구조도 만족스러움
- 현대적 운영체제는 디스크 데이터를 메모리에 아주 적극적으로 캐싱
    - 필요하다면 가용한 메모리 전부를 디스크 데이터를 캐시하는데 활용하기도 함
    - WAL도 OS가 제공하는 디스크 캐시 기능을 적극적으로 활용함


### 메시지 자료 구조

> 메시지 구조는 높은 대역폭 달성의 열쇠
> 
- 메시지 자료 구조는 생산자, 메시지 큐, 그리고 소비자 사이의 예약
- 본 설계안은 메시지가 큐를 거쳐 소비자에게 전달되는 과정에서 불필요한 복사가 일어나지 않도록 함으로써 높은 대역폭을 달성
- 시스템 컴포넌트 중, 이 계약을 있는 그대로 받아들이지 못하는 것이 있으면 메시지는 변경되어야하고 그 과정에서 값비싼 복사(copy)가 발생
- 그 결과로 시스템 전반의 성능응 심각하게 낮아질 수 있음
- 메시지 자료 구조의 스키마 사례
    
    
    | 필드 이름 | 데이터 자료형 |
    | --- | --- |
    | key | byte[] |
    | value | byte[] |
    | topic | string |
    | partition | integer |
    | offset | long |
    | timestamp | long |
    | size | integer |
    | crc | integer |

### 메시지 키

> 메시지의 키(key)는 파티션을 정할 때 사용
> 
- 키가 주어지지 않은 메시지의 파티션은 무작위적으로 결정
- 키가 주어진 경우 파티션은 hash(key) % numPartitions 공식에 따라 결정
    - 더 유연한 설계가 필요하다면 생산자는 파티션 선정 메커니즘을 직접 정의할 수도 있음
    - 키는 파티션 번호가 아니라는 점에 유의 필요
- 키는 문자열일 수도 있고 숫자일 수도 있음
    - 키에는 비즈니스 관련 정보가 담기는 것이 보통
    - 파티션 번호는 메시지 큐 내부적으로 사용되는 개념이므로 클라이언트에 노출되어서는 X
- 키를 파티션에 대응시키는 알고리즘을 적절히 정의해 놓으면 파티션의 수가 달라져도 모든 파티션에 메시지가 계속 균등히 분산되도록 할 수 있음


### 메시지 값

> 메시지 값은 메시지의 내용, 즉 페이로드를 말한다
> 
- 메시지 값은 일반 텍스트일 수도 있고 압축된 이진 블록일 수도 있음
- 유의사항:
    - 메시지의 키 그리고 메시지의 값은 키-밸류 저장소에서 이야기하는 키나 값과 다름
    - 키-밸류 저장소의 경우 키는 고유하므로 원하는 값은 키를 통해서 찾을 수 있음
    - 하지만 메시지의 키는 메시지마다 고유할 필요가 없음
    - 심지어 메시지에 반드시 키를 두는 것도 아님
    - 키를 사용해 값을 찾을 필요도 없음

### 메시지의 기타 필드

- 토픽: 메시지가 속한 토픽의 이름
- 파티션: 메시지가 속한 파티션의 ID
- 오프셋:
    - 파티션 내 메시지의 위치
    - 메시지는 토픽, 파티션, 오프셋 세 가지 정보를 알면 찾을 수 있음
- 타임스탬프: 메시지가 저장된 시각
- 크기: 메시지의 크기
- CRC:
    - 순환 중복 검사(Cyclic Redundancy Check)
    - 주어진 `데이터의 무결성을 보장`하는데 이용
- 이외에도 더 많은 기능을 지원하기 위한 선택적 필드가 있을 수 있음
    - 가령 태그 필드가 있다면 메시지를 태그 기반으로 필터링 가능


### 일괄 처리

> 일괄 처리는 본 설계안에서 광범위하게 사용되며, 생산자, 소비자, 메시지 큐는 메시지를 가급적 일괄 처리함
> 
- 일괄 처리는 시스템 성능에 매우 중요함
- 일괄 처리가 성능 개선에 중요한 이유:
    - 운영체제로 하여금 여러 메시지를 한 번의 네트워크 요청으로 전송할 수 있도록 함
        - 값비싼 네트워크 왕복 비용 제거 가능
    - 브로커가 여러 메시지를 한 번에 로그에 기록하면 더 큰 규모의 순차 쓰기 연산 발생
        - 운영체제가 관리하는 디스크 캐시에서 더 큰 규모의 연속된 공간 점유
        - 그 결과로 더 높은 디스크 접근 대역폭 달성
- 높은 대역폭과 낮은 응답 지연은 동시에 달성하기 어려운 목표
    - 시스템이 낮은 응답 지연이 중요한 전통적 메시지 큐로 이용된다면 일괄 처리 메시지 양은 낮춤
        - 이렇게 진행하면 디스크 성능은 다소 낮아짐
        - 처리량을 높여야 한다면 토픽당 파티션의 수는 느림
        - 이렇게 진행해야 낮아진 순차 쓰기 연산 대역폭을 벌충할 수 있음

## 생산자 측 작업 흐름

> 생산자가 어떤 파티션에 메시지를 보내야한다고 가정해보자
어느 브로커에 연결해야할까?
한 가지 해결책은 라우팅 계층을 도입하는 것이다
> 
- **설계안**
- 라우팅 계층은 ‘적절한’ 브로커에 메시지를 보내는 역할 담당
- 브로커를 여러 개로 복제하여 운영하는 경우, 메시지를 받을 ‘적절한’ 브로커는 `리더 브로커`
- 생산자는 `토픽-A`의 `파티션-1`로 메시지를 보내고자 하는 경우
1. 생산자는 메시지를 라우팅 계층으로 전송
2. 라우팅 계층은 메타데이터 저장소에서 사본 분산 계획(replica distribution plan)을 읽어 자기 캐시에 보관
3. 메시지가 도착하면 라우팅 계층은 파티션-1의 리더 사본에 전송
4. 리더 사본이 우선 메시지를 받고 해당 리더를 따르는 다른 사본은 해당 리더로부터 데이터를 받음
5. ‘충분한’ 수의 사본이 동기화되면 리더는 데이터를 디스크에 기록(commit) - 데이터가 소비 가능 상태가 되는 시점
6. 기록이 끝나고 나면 생산자에게 회신

- 리더와 사본이 필요한 이유는 무엇일까? → `장애 감내(fault tolerance)`가 가능한 시스템을 만들이 위함
- 지금까지 설명한 방법은 동작은 하지만 몇 가지 단점 존재:
    - 라우팅 계층을 도입하면 거쳐야 할 네트워크 노드가 하나 더 늘어나게 되므로 오버헤드가 발생하여 네트워크 전송 지연이 늘어남
    - 일괄 처리가 가능하면 효율을 많이 높일 수 있는데 그런 부분은 고혀하지 않은 설계

- **수정 설계안**
- 변경된 설계안은 라우팅 계층을 생산자 내부로 편입시키고 버퍼를 도입
- 생산자 클라이언트 라이브러리의 일부로 생산자에 설치
- 해당 작업의 장점:
    - 네트워크를 거칠 필요가 줄어들기 때문에 전송 지연도 줄어듬
    - 생산자는 메시지를 어느 파티션에 보낼지 결정하는 자신만의 로직을 가질 수 있음
    - 전송할 메시지를 버퍼 메모리에 보관했다가 목적지로 일괄 전송하여 대역폭을 높일 수 있음
- 얼마나 많은 메시지를 일괄 처리하는 것이 좋을까? → 대역폭과 응답 지연 사이에서 타협점을 찾는 문제
    - 일괄 처리할 메시지의 양을 늘리면 대역폭은 늘어나지만 응답 속도는 느려짐
        - 일괄 처리가 가능할 양의 메시지가 쌓이길 기다려야 하기 때문
    - 양을 줄이면 메시지는 더 빨리 보낼 수 있으니 지연은 줄어들지만 대역폭은 손해를 봄
- 생산자는 메시지 큐의 용도를 감안하여 일괄 처리 메시지 양을 조정해야함

## 소비자 측 작업 흐름

> 소비자는 특정 파티션의 오프셋을 주고 해당 위치에서부터 이벤트를 묶어 가져온다
> 

### 푸시 vs 폴

> 중요하게 생각해봐야할 것은 브로커가 데이터를 소비자에게 보낼 것이냐 아니면 소비자가 브로커에서 가져갈 것이냐 하는 부분
> 

### 푸시 모델

- 장점:
    - 낮은 지연: 브로커는 메시지를 받는 즉시 소비자에게 전송 가능
- 단점:
    - 소비자가 메시지를 처리하는 속도가 생산자가 메시지를 만드는 속도보다 느릴 경우, 소비자에게 큰 부하가 걸릴 가능성이 있음
    - 생산자가 데이터 전송 속도를 좌우하므로, 소비자는 항상 그에 맞는 처리가 가능한 컴퓨팅 자원을 준비해두어야함

### 풀 모델

- 장점:
    - 메시지를 소비하는 속도는 소비자가 알아서 결정
        - 어떤 소비자는 메시지를 실시간으로 가져가고 어떤 소비자는 일괄로 가져가는 등의 구성이 가능
    - 메시지를 소비하는 속도가 생산 속도보다 느려지면 소비자를 늘려 해결할 수도 있고 아니면 생산 속도를 따라잡을 때까지 기다려도 됨
    - 일괄 처리에 적합:
        - 푸시 모델의 경우 브로커는 소비자가 메시지를 바로 처리할 여건이 되는지 알지 못함
        - 따라서 소비자가 제때 처리하지 못한 메시지는 버퍼에 쌓여 처리를 기다리게 됨
        - 반면 풀 모델의 경우 소비자는 지난번 마지막으로 가져간 로그 위치 다음에 오는 모든 메시지를(혹은 설정된 최대 개수 만큼) 한 번에 가져갈 수 있음 → 데이터의 공격적 일괄 처리에 좀 더 적합함
- 단점:
    - 브로커에 메시지가 없어도 소비자는 계속 데이터를 끌어가려 시도함
        - 소비자 측 자원이 낭비됨
    - 해당 문제를 극복하기 위해 많은 메시지 큐가 `롱 폴링(long polling)` 모드를 지원
        - 당장은 가져갈 메시지가 업더라도 일정 시간은 기다리도록 함
- 이러한 이유로 대부분 메시지 큐는 푸시 모델 대신 풀 모델을 지원함

- **풀 모델 아키텍처**
1. 그룹-1에 합류하고 토픽-A를 구독하길 원하는 새로운 소비자가 있다고 가정
2. 그 소비자는 그룹 이름을 해싱하여 접속할 브로커 노드를 찾음
3. 따라서 같은 그룹의 모든 소비자는 같은 브로커에 접속
    1. 이런 브로커를 해당 소비자 그룹의 코디네이터라고 부름
    2. 이름이 비슷하긴 하지만 소비자 그룹 코데네이터는 조정 서비스(coordination service)와는 다름
        1. 코디네이터는 소비자 그룹의 조정 작업만 담당
        2. 반면 조정 서비스는 브로커 클러스터 조정 작업 담당
4. 코디네이터는 해당 소비자를 그룹에 참여시키고 파티션-2를 해당 소비자에 할당
    1. 파티션 배치 정책에는 라운드로빈, 범위 기반 정책 등 여러가지 존재
5. 소비자는 마지막으로 소비한 오프셋 이후 메시지를 가져옴
    1. 오프셋 정보는 상태 저장소에 위치함
6. 소비자는 메시지를 처리하고 새로운 오프셋을 브로커에 전송
    1. 데이터 처리와 오프셋 갱신 순서는 메시지 전송 시맨틱에 영향을 미침

### 소비자 재조정

> 소비자 재조정(consumer rebalancing)은 어떤 소비자가 어떤 파티션을 책임지는지 다시 정하는 프로세스
> 
- 해당 프로세스는 새로운 소비자가 합류하거나, 기존 소비자가 그룹을 떠나거나, 어떤 소비자에 장애가 발생하거나, 파티션들이 조정되는 경우에 시작될 수 있음
- 해당 절차에 `코디네이터`가 중요한 역할을 함
- 코디네이터는 **소비자 재조정을 위해 소비자들과 통신하는 브로커 노드**
- 코디네이터는 소비자로부터 오는 박동(heartbeat) 메시지를 살피고 각 소비자의 파티션 내 오프셋 정보를 관리
- 코디네이터는 자신에 연결한 소비자 목록을 유지
    - 해당 목록에 변화가 생기면 코디네이터는 해당 그룹의 새 리더를 선출
    - 새 리더는 새 파티션 계획(partition dispatch plan)을 만들고 코디네이터에게 전달
    - 코디네이터는 해당 계획을 그룹 내 다른 모든 소비자에게 전파

- 분산 시스템이므로 소비자는 네트워크 이슈를 비롯한 다양한 장애를 겪을 수 있음
- 코디네이터 관점에서 보면 소비자에게 발생한 장애는 박동 신호가 사라지는 현상을 통해 감지 가능
- 소비자 장애를 감지하면 코디네이터는 재조정 프로세스를 시작하여 파티션을 재배치

### 재조정 시나리오 - 소비자 추가 과정

- **새로운 소비자의 합류 로직**
- 그룹 내 소비자 수는 두 개, 구독하는 토픽에 파티션은 네 개로 가정
1. 시작 지점의 그룹 안에는 소비자 A만 있는 상태
    1. 소비자 A는 모든 파티션의 메시지를 소비
    2. 코디네이터에게 지속적으로 박동 메시지를 전송
2. 소비자 B가 그룹에 합류 요청
3. 코디네이터는 소비자 재조정이 필요한 시점이라고 판단하고 모든 소비자에게 그 사실을 수동적으로 통지
    1. 소비자 A의 박동 메시지가 왔을 때, 그 응답으로 그룹에 다시 합류하라고 알림
4. 모든 소비자가 그룹에 다시 합류하면 코디네이터는 그 가운데 하나를 리더로 선출하고 모든 소비자에게 해당 사실 전파
5. 리더는 파티션 배치 계획을 생성한 다음 코디네이터에게 전송
    1. 리더 외의 소비자는 코디네이터에게 요청하여 파티션 배치 계획을 받아옴
6. 소비자는 자신에게 배치된 파티션에서 메시지를 가져오기 시작함

### 재조정 시나리오 - 소비자 삭제 과정

- **새로운 소비자의 이탈 로직**
1. 소비자 A와 B는 같은 소비자 그룹 멤버
2. 소비자 A가 가동 중단이 필요하여 그룹 탈퇴 요청
3. 코디네이터는 소비자 재조정이 필요한 시점으로 판단하고 소비자 B의 박동 메시지를 수신하면 그룹에 다시 합류할 것을 지시
4. 나머지 절차는 이전 시나리오와 동일

### 재조정 시나리오 - 소비자의 비정상적 가동 중단으로 인한 처리 흐름

1. 소비자 A와 B는 같은 소비자 그룹 멤버로, 지속적으로 코디네이터에게 박동 메시지 전달
2. 소비자 A에 장애가 발생하면 더 이상의 박동 메시지는 코디네이터에게 전달되지 못함
3. 코디네이터는 일정 시간 동안 해당 상황이 지속되면 해당 소비자가 사라진 것으로 판단
4. 코디네이터는 소비자 재조정 프로세스 개시
5. 나머지 절차는 이전 시나리오와 동일

### 상태 저장소








